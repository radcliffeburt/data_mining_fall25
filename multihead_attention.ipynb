{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d05226",
   "metadata": {},
   "source": [
    "Multihead attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6868eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radcl\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\_subclasses\\functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "186cdd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.nn.Embedding(4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36ca8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad8c234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd75643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Creating a batch of inputs\n",
    "batches = torch.stack((inputs,inputs), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c25fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1308, -0.6282, -0.5783,  2.4659, -1.0366, -2.0084,  0.2694,\n",
      "          -0.5123],\n",
      "         [-1.5517,  0.2296, -0.4225,  0.5770,  0.0938,  1.3966, -1.2605,\n",
      "           0.4180],\n",
      "         [-1.3177,  1.0482,  1.7603,  1.6768, -0.6987,  0.8940, -0.2337,\n",
      "          -1.6383],\n",
      "         [ 0.6325, -0.2742, -0.2992,  0.2525, -1.1736, -0.5618,  1.2594,\n",
      "          -1.8560]],\n",
      "\n",
      "        [[ 0.1308, -0.6282, -0.5783,  2.4659, -1.0366, -2.0084,  0.2694,\n",
      "          -0.5123],\n",
      "         [-1.5517,  0.2296, -0.4225,  0.5770,  0.0938,  1.3966, -1.2605,\n",
      "           0.4180],\n",
      "         [-1.3177,  1.0482,  1.7603,  1.6768, -0.6987,  0.8940, -0.2337,\n",
      "          -1.6383],\n",
      "         [ 0.6325, -0.2742, -0.2992,  0.2525, -1.1736, -0.5618,  1.2594,\n",
      "          -1.8560]]])\n",
      "Batches Shape: torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# output dimension\n",
    "d_out = 12\n",
    "d_in = 4\n",
    "num_heads = 4\n",
    "assert( d_out % num_heads ==0), \"Error: num_heads must be divisible by d_out, try again\"\n",
    "\n",
    "\n",
    "b, num_tokens, d_in = batches.shape\n",
    "print(batches)\n",
    "print(\"Batches Shape:\", batches.shape)\n",
    "\n",
    "    \n",
    "\n",
    "# make sure d_out is always divisible by num_heads, otherwise the matrix multiplication does not work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ce63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a sequence of cells, go step-by-step through the same calculation of\n",
    "# queries and attention scores that the MultiHeadAttention class does.\n",
    "# At each step, print the tensors and their shapes to see why reshaping is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5ffffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=8, out_features=12, bias=False) Linear(in_features=8, out_features=12, bias=False) Linear(in_features=8, out_features=12, bias=False)\n",
      "Queries: tensor([[[ 0.1164, -0.6811,  0.1669,  0.0357, -0.1414,  0.2240,  0.1928,\n",
      "          -0.5178, -0.4856, -0.8122, -0.0802, -0.2613],\n",
      "         [-0.7732,  0.0645, -0.6681, -0.1394, -0.0730, -0.1375,  0.5155,\n",
      "           0.2867, -0.6223,  0.5112, -0.3628,  0.0926],\n",
      "         [ 0.2868, -0.3071,  0.9084,  0.1792,  0.0425, -0.3077, -0.8131,\n",
      "           0.7887,  1.0414, -0.3755, -0.6892,  0.3011],\n",
      "         [-0.9935,  0.1487, -0.6568,  0.4441,  0.5104, -0.6038, -0.1148,\n",
      "           1.0410,  0.0992,  0.2737, -0.4814,  0.8268]],\n",
      "\n",
      "        [[ 0.1164, -0.6811,  0.1669,  0.0357, -0.1414,  0.2240,  0.1928,\n",
      "          -0.5178, -0.4856, -0.8122, -0.0802, -0.2613],\n",
      "         [-0.7732,  0.0645, -0.6681, -0.1394, -0.0730, -0.1375,  0.5155,\n",
      "           0.2867, -0.6223,  0.5112, -0.3628,  0.0926],\n",
      "         [ 0.2868, -0.3071,  0.9084,  0.1792,  0.0425, -0.3077, -0.8131,\n",
      "           0.7887,  1.0414, -0.3755, -0.6892,  0.3011],\n",
      "         [-0.9935,  0.1487, -0.6568,  0.4441,  0.5104, -0.6038, -0.1148,\n",
      "           1.0410,  0.0992,  0.2737, -0.4814,  0.8268]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([2, 4, 12])\n",
      "Keys: tensor([[[ 0.6336, -0.1615,  0.0029,  0.2860, -0.4014, -0.4787, -0.1709,\n",
      "          -0.6720, -0.0377,  0.1992,  0.4111, -0.3925],\n",
      "         [ 0.4561, -0.1157, -0.3743, -0.0279, -0.4213, -0.1092, -0.1826,\n",
      "          -0.2872, -0.5164,  0.1998,  0.0280,  0.2570],\n",
      "         [-1.0950,  0.5752,  0.6777, -0.0924, -0.2529, -0.0602, -0.0630,\n",
      "           0.5929,  0.4133, -1.0773,  0.0822, -0.6848],\n",
      "         [-0.1041,  0.4852,  0.3652,  0.8319, -0.0936, -0.8739, -0.4472,\n",
      "          -0.4092, -1.0539, -0.0505,  0.1851,  0.5515]],\n",
      "\n",
      "        [[ 0.6336, -0.1615,  0.0029,  0.2860, -0.4014, -0.4787, -0.1709,\n",
      "          -0.6720, -0.0377,  0.1992,  0.4111, -0.3925],\n",
      "         [ 0.4561, -0.1157, -0.3743, -0.0279, -0.4213, -0.1092, -0.1826,\n",
      "          -0.2872, -0.5164,  0.1998,  0.0280,  0.2570],\n",
      "         [-1.0950,  0.5752,  0.6777, -0.0924, -0.2529, -0.0602, -0.0630,\n",
      "           0.5929,  0.4133, -1.0773,  0.0822, -0.6848],\n",
      "         [-0.1041,  0.4852,  0.3652,  0.8319, -0.0936, -0.8739, -0.4472,\n",
      "          -0.4092, -1.0539, -0.0505,  0.1851,  0.5515]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([2, 4, 12])\n",
      "Values: tensor([[[ 0.0490, -0.9331,  0.7512,  0.3188, -0.6036,  0.4032,  0.1633,\n",
      "          -0.2368, -0.4353,  0.1264, -0.3258,  0.4194],\n",
      "         [ 0.2383,  0.0684, -0.2507, -0.3842,  0.1083, -0.0187, -0.6111,\n",
      "          -0.7375,  0.6781,  0.2154,  0.2953, -0.6759],\n",
      "         [-1.1844, -0.8051, -0.5278, -0.1273, -1.4156, -0.0485,  0.7133,\n",
      "           0.9641, -0.3673, -0.7760, -1.1335,  0.3381],\n",
      "         [-0.2266, -0.3733, -0.3341, -0.8367, -0.1025, -0.5134, -0.5376,\n",
      "          -0.7594,  0.8257, -0.8756,  0.3602, -0.8530]],\n",
      "\n",
      "        [[ 0.0490, -0.9331,  0.7512,  0.3188, -0.6036,  0.4032,  0.1633,\n",
      "          -0.2368, -0.4353,  0.1264, -0.3258,  0.4194],\n",
      "         [ 0.2383,  0.0684, -0.2507, -0.3842,  0.1083, -0.0187, -0.6111,\n",
      "          -0.7375,  0.6781,  0.2154,  0.2953, -0.6759],\n",
      "         [-1.1844, -0.8051, -0.5278, -0.1273, -1.4156, -0.0485,  0.7133,\n",
      "           0.9641, -0.3673, -0.7760, -1.1335,  0.3381],\n",
      "         [-0.2266, -0.3733, -0.3341, -0.8367, -0.1025, -0.5134, -0.5376,\n",
      "          -0.7594,  0.8257, -0.8756,  0.3602, -0.8530]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([2, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "#setup parameter\n",
    "W_query = nn.Linear(d_in, d_out, bias = False)\n",
    "W_key = nn.Linear(d_in, d_out, bias = False)\n",
    "W_value = nn.Linear(d_in, d_out, bias = False)\n",
    "\n",
    "print(W_query,W_key,W_value)\n",
    "\n",
    "keys = W_key(batches)\n",
    "queries = W_query(batches)\n",
    "values = W_value(batches)\n",
    "\n",
    "print(\"Queries:\",queries,queries.shape)\n",
    "print(\"Keys:\",keys,keys.shape)\n",
    "print(\"Values:\",values, values.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c801b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries reshaped: tensor([[[[ 0.1164, -0.6811,  0.1669],\n",
      "          [-0.7732,  0.0645, -0.6681],\n",
      "          [ 0.2868, -0.3071,  0.9084],\n",
      "          [-0.9935,  0.1487, -0.6568]],\n",
      "\n",
      "         [[ 0.0357, -0.1414,  0.2240],\n",
      "          [-0.1394, -0.0730, -0.1375],\n",
      "          [ 0.1792,  0.0425, -0.3077],\n",
      "          [ 0.4441,  0.5104, -0.6038]],\n",
      "\n",
      "         [[ 0.1928, -0.5178, -0.4856],\n",
      "          [ 0.5155,  0.2867, -0.6223],\n",
      "          [-0.8131,  0.7887,  1.0414],\n",
      "          [-0.1148,  1.0410,  0.0992]],\n",
      "\n",
      "         [[-0.8122, -0.0802, -0.2613],\n",
      "          [ 0.5112, -0.3628,  0.0926],\n",
      "          [-0.3755, -0.6892,  0.3011],\n",
      "          [ 0.2737, -0.4814,  0.8268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1164, -0.6811,  0.1669],\n",
      "          [-0.7732,  0.0645, -0.6681],\n",
      "          [ 0.2868, -0.3071,  0.9084],\n",
      "          [-0.9935,  0.1487, -0.6568]],\n",
      "\n",
      "         [[ 0.0357, -0.1414,  0.2240],\n",
      "          [-0.1394, -0.0730, -0.1375],\n",
      "          [ 0.1792,  0.0425, -0.3077],\n",
      "          [ 0.4441,  0.5104, -0.6038]],\n",
      "\n",
      "         [[ 0.1928, -0.5178, -0.4856],\n",
      "          [ 0.5155,  0.2867, -0.6223],\n",
      "          [-0.8131,  0.7887,  1.0414],\n",
      "          [-0.1148,  1.0410,  0.0992]],\n",
      "\n",
      "         [[-0.8122, -0.0802, -0.2613],\n",
      "          [ 0.5112, -0.3628,  0.0926],\n",
      "          [-0.3755, -0.6892,  0.3011],\n",
      "          [ 0.2737, -0.4814,  0.8268]]]], grad_fn=<ReshapeAliasBackward0>) Q shape: torch.Size([2, 4, 4, 3])\n",
      "Keys reshaped: tensor([[[[ 0.6336, -0.1615,  0.0029],\n",
      "          [ 0.4561, -0.1157, -0.3743],\n",
      "          [-1.0950,  0.5752,  0.6777],\n",
      "          [-0.1041,  0.4852,  0.3652]],\n",
      "\n",
      "         [[ 0.2860, -0.4014, -0.4787],\n",
      "          [-0.0279, -0.4213, -0.1092],\n",
      "          [-0.0924, -0.2529, -0.0602],\n",
      "          [ 0.8319, -0.0936, -0.8739]],\n",
      "\n",
      "         [[-0.1709, -0.6720, -0.0377],\n",
      "          [-0.1826, -0.2872, -0.5164],\n",
      "          [-0.0630,  0.5929,  0.4133],\n",
      "          [-0.4472, -0.4092, -1.0539]],\n",
      "\n",
      "         [[ 0.1992,  0.4111, -0.3925],\n",
      "          [ 0.1998,  0.0280,  0.2570],\n",
      "          [-1.0773,  0.0822, -0.6848],\n",
      "          [-0.0505,  0.1851,  0.5515]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6336, -0.1615,  0.0029],\n",
      "          [ 0.4561, -0.1157, -0.3743],\n",
      "          [-1.0950,  0.5752,  0.6777],\n",
      "          [-0.1041,  0.4852,  0.3652]],\n",
      "\n",
      "         [[ 0.2860, -0.4014, -0.4787],\n",
      "          [-0.0279, -0.4213, -0.1092],\n",
      "          [-0.0924, -0.2529, -0.0602],\n",
      "          [ 0.8319, -0.0936, -0.8739]],\n",
      "\n",
      "         [[-0.1709, -0.6720, -0.0377],\n",
      "          [-0.1826, -0.2872, -0.5164],\n",
      "          [-0.0630,  0.5929,  0.4133],\n",
      "          [-0.4472, -0.4092, -1.0539]],\n",
      "\n",
      "         [[ 0.1992,  0.4111, -0.3925],\n",
      "          [ 0.1998,  0.0280,  0.2570],\n",
      "          [-1.0773,  0.0822, -0.6848],\n",
      "          [-0.0505,  0.1851,  0.5515]]]], grad_fn=<ReshapeAliasBackward0>) K shape: torch.Size([2, 4, 4, 3])\n",
      "Values reshaped: tensor([[[[ 0.0490, -0.9331,  0.7512],\n",
      "          [ 0.2383,  0.0684, -0.2507],\n",
      "          [-1.1844, -0.8051, -0.5278],\n",
      "          [-0.2266, -0.3733, -0.3341]],\n",
      "\n",
      "         [[ 0.3188, -0.6036,  0.4032],\n",
      "          [-0.3842,  0.1083, -0.0187],\n",
      "          [-0.1273, -1.4156, -0.0485],\n",
      "          [-0.8367, -0.1025, -0.5134]],\n",
      "\n",
      "         [[ 0.1633, -0.2368, -0.4353],\n",
      "          [-0.6111, -0.7375,  0.6781],\n",
      "          [ 0.7133,  0.9641, -0.3673],\n",
      "          [-0.5376, -0.7594,  0.8257]],\n",
      "\n",
      "         [[ 0.1264, -0.3258,  0.4194],\n",
      "          [ 0.2154,  0.2953, -0.6759],\n",
      "          [-0.7760, -1.1335,  0.3381],\n",
      "          [-0.8756,  0.3602, -0.8530]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0490, -0.9331,  0.7512],\n",
      "          [ 0.2383,  0.0684, -0.2507],\n",
      "          [-1.1844, -0.8051, -0.5278],\n",
      "          [-0.2266, -0.3733, -0.3341]],\n",
      "\n",
      "         [[ 0.3188, -0.6036,  0.4032],\n",
      "          [-0.3842,  0.1083, -0.0187],\n",
      "          [-0.1273, -1.4156, -0.0485],\n",
      "          [-0.8367, -0.1025, -0.5134]],\n",
      "\n",
      "         [[ 0.1633, -0.2368, -0.4353],\n",
      "          [-0.6111, -0.7375,  0.6781],\n",
      "          [ 0.7133,  0.9641, -0.3673],\n",
      "          [-0.5376, -0.7594,  0.8257]],\n",
      "\n",
      "         [[ 0.1264, -0.3258,  0.4194],\n",
      "          [ 0.2154,  0.2953, -0.6759],\n",
      "          [-0.7760, -1.1335,  0.3381],\n",
      "          [-0.8756,  0.3602, -0.8530]]]], grad_fn=<ReshapeAliasBackward0>) V shape: torch.Size([2, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "queries = queries.view(b,num_tokens, num_heads, d_out // num_heads)\n",
    "keys = keys.view(b,num_tokens, num_heads, d_out // num_heads)\n",
    "values = values.view(b,num_tokens, num_heads, d_out // num_heads)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Queries reshaped:\",queries,\"Q shape:\",queries.shape)\n",
    "print(\"Keys reshaped:\",keys,\"K shape:\",keys.shape)\n",
    "print(\"Values reshaped:\",values,\"V shape:\",values.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "063f260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries transposed: tensor([[[[ 0.1164, -0.6811,  0.1669],\n",
      "          [ 0.0357, -0.1414,  0.2240],\n",
      "          [ 0.1928, -0.5178, -0.4856],\n",
      "          [-0.8122, -0.0802, -0.2613]],\n",
      "\n",
      "         [[-0.7732,  0.0645, -0.6681],\n",
      "          [-0.1394, -0.0730, -0.1375],\n",
      "          [ 0.5155,  0.2867, -0.6223],\n",
      "          [ 0.5112, -0.3628,  0.0926]],\n",
      "\n",
      "         [[ 0.2868, -0.3071,  0.9084],\n",
      "          [ 0.1792,  0.0425, -0.3077],\n",
      "          [-0.8131,  0.7887,  1.0414],\n",
      "          [-0.3755, -0.6892,  0.3011]],\n",
      "\n",
      "         [[-0.9935,  0.1487, -0.6568],\n",
      "          [ 0.4441,  0.5104, -0.6038],\n",
      "          [-0.1148,  1.0410,  0.0992],\n",
      "          [ 0.2737, -0.4814,  0.8268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1164, -0.6811,  0.1669],\n",
      "          [ 0.0357, -0.1414,  0.2240],\n",
      "          [ 0.1928, -0.5178, -0.4856],\n",
      "          [-0.8122, -0.0802, -0.2613]],\n",
      "\n",
      "         [[-0.7732,  0.0645, -0.6681],\n",
      "          [-0.1394, -0.0730, -0.1375],\n",
      "          [ 0.5155,  0.2867, -0.6223],\n",
      "          [ 0.5112, -0.3628,  0.0926]],\n",
      "\n",
      "         [[ 0.2868, -0.3071,  0.9084],\n",
      "          [ 0.1792,  0.0425, -0.3077],\n",
      "          [-0.8131,  0.7887,  1.0414],\n",
      "          [-0.3755, -0.6892,  0.3011]],\n",
      "\n",
      "         [[-0.9935,  0.1487, -0.6568],\n",
      "          [ 0.4441,  0.5104, -0.6038],\n",
      "          [-0.1148,  1.0410,  0.0992],\n",
      "          [ 0.2737, -0.4814,  0.8268]]]], grad_fn=<TransposeBackward0>) Shape: torch.Size([2, 4, 4, 3])\n",
      "Keys transposed: tensor([[[[ 0.6336, -0.1615,  0.0029],\n",
      "          [ 0.2860, -0.4014, -0.4787],\n",
      "          [-0.1709, -0.6720, -0.0377],\n",
      "          [ 0.1992,  0.4111, -0.3925]],\n",
      "\n",
      "         [[ 0.4561, -0.1157, -0.3743],\n",
      "          [-0.0279, -0.4213, -0.1092],\n",
      "          [-0.1826, -0.2872, -0.5164],\n",
      "          [ 0.1998,  0.0280,  0.2570]],\n",
      "\n",
      "         [[-1.0950,  0.5752,  0.6777],\n",
      "          [-0.0924, -0.2529, -0.0602],\n",
      "          [-0.0630,  0.5929,  0.4133],\n",
      "          [-1.0773,  0.0822, -0.6848]],\n",
      "\n",
      "         [[-0.1041,  0.4852,  0.3652],\n",
      "          [ 0.8319, -0.0936, -0.8739],\n",
      "          [-0.4472, -0.4092, -1.0539],\n",
      "          [-0.0505,  0.1851,  0.5515]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6336, -0.1615,  0.0029],\n",
      "          [ 0.2860, -0.4014, -0.4787],\n",
      "          [-0.1709, -0.6720, -0.0377],\n",
      "          [ 0.1992,  0.4111, -0.3925]],\n",
      "\n",
      "         [[ 0.4561, -0.1157, -0.3743],\n",
      "          [-0.0279, -0.4213, -0.1092],\n",
      "          [-0.1826, -0.2872, -0.5164],\n",
      "          [ 0.1998,  0.0280,  0.2570]],\n",
      "\n",
      "         [[-1.0950,  0.5752,  0.6777],\n",
      "          [-0.0924, -0.2529, -0.0602],\n",
      "          [-0.0630,  0.5929,  0.4133],\n",
      "          [-1.0773,  0.0822, -0.6848]],\n",
      "\n",
      "         [[-0.1041,  0.4852,  0.3652],\n",
      "          [ 0.8319, -0.0936, -0.8739],\n",
      "          [-0.4472, -0.4092, -1.0539],\n",
      "          [-0.0505,  0.1851,  0.5515]]]], grad_fn=<TransposeBackward0>) Shape: torch.Size([2, 4, 4, 3])\n",
      "values transposed: tensor([[[[ 0.0490, -0.9331,  0.7512],\n",
      "          [ 0.3188, -0.6036,  0.4032],\n",
      "          [ 0.1633, -0.2368, -0.4353],\n",
      "          [ 0.1264, -0.3258,  0.4194]],\n",
      "\n",
      "         [[ 0.2383,  0.0684, -0.2507],\n",
      "          [-0.3842,  0.1083, -0.0187],\n",
      "          [-0.6111, -0.7375,  0.6781],\n",
      "          [ 0.2154,  0.2953, -0.6759]],\n",
      "\n",
      "         [[-1.1844, -0.8051, -0.5278],\n",
      "          [-0.1273, -1.4156, -0.0485],\n",
      "          [ 0.7133,  0.9641, -0.3673],\n",
      "          [-0.7760, -1.1335,  0.3381]],\n",
      "\n",
      "         [[-0.2266, -0.3733, -0.3341],\n",
      "          [-0.8367, -0.1025, -0.5134],\n",
      "          [-0.5376, -0.7594,  0.8257],\n",
      "          [-0.8756,  0.3602, -0.8530]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0490, -0.9331,  0.7512],\n",
      "          [ 0.3188, -0.6036,  0.4032],\n",
      "          [ 0.1633, -0.2368, -0.4353],\n",
      "          [ 0.1264, -0.3258,  0.4194]],\n",
      "\n",
      "         [[ 0.2383,  0.0684, -0.2507],\n",
      "          [-0.3842,  0.1083, -0.0187],\n",
      "          [-0.6111, -0.7375,  0.6781],\n",
      "          [ 0.2154,  0.2953, -0.6759]],\n",
      "\n",
      "         [[-1.1844, -0.8051, -0.5278],\n",
      "          [-0.1273, -1.4156, -0.0485],\n",
      "          [ 0.7133,  0.9641, -0.3673],\n",
      "          [-0.7760, -1.1335,  0.3381]],\n",
      "\n",
      "         [[-0.2266, -0.3733, -0.3341],\n",
      "          [-0.8367, -0.1025, -0.5134],\n",
      "          [-0.5376, -0.7594,  0.8257],\n",
      "          [-0.8756,  0.3602, -0.8530]]]], grad_fn=<TransposeBackward0>) Shape: torch.Size([2, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Transpose by head\n",
    "queries = queries.transpose(1,2)\n",
    "keys = keys.transpose(1,2)\n",
    "values = values.transpose(1,2)\n",
    "\n",
    "print(\"queries transposed:\", queries, \"Shape:\", queries.shape)\n",
    "print(\"Keys transposed:\", keys, \"Shape:\", keys.shape)\n",
    "print(\"values transposed:\", values, \"Shape:\", values.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "138088ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores: tensor([[[[ 0.1842,  0.2268,  0.4314, -0.3223],\n",
      "          [ 0.0461, -0.0402,  0.0805, -0.1389],\n",
      "          [ 0.2044,  0.4954,  0.3333,  0.0161],\n",
      "          [-0.5024, -0.0750,  0.2026, -0.0922]],\n",
      "\n",
      "         [[-0.1101,  0.0674,  0.4677, -0.3244],\n",
      "          [-0.0037,  0.0497,  0.1174, -0.0652],\n",
      "          [ 0.4349, -0.0672,  0.1449, -0.0489],\n",
      "          [ 0.2405,  0.1285, -0.0370,  0.1158]],\n",
      "\n",
      "         [[ 0.1249, -0.0035,  0.1753, -0.9563],\n",
      "          [-0.3803, -0.0088, -0.1132,  0.0212],\n",
      "          [ 2.0497, -0.1870,  0.9492,  0.2277],\n",
      "          [ 0.2188,  0.1909, -0.2606,  0.1416]],\n",
      "\n",
      "         [[-0.0643, -0.2665,  1.0756, -0.2845],\n",
      "          [-0.0191,  0.8494,  0.2290, -0.2609],\n",
      "          [ 0.5532, -0.2796, -0.4791,  0.2532],\n",
      "          [ 0.0399, -0.4498, -0.7968,  0.3531]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1842,  0.2268,  0.4314, -0.3223],\n",
      "          [ 0.0461, -0.0402,  0.0805, -0.1389],\n",
      "          [ 0.2044,  0.4954,  0.3333,  0.0161],\n",
      "          [-0.5024, -0.0750,  0.2026, -0.0922]],\n",
      "\n",
      "         [[-0.1101,  0.0674,  0.4677, -0.3244],\n",
      "          [-0.0037,  0.0497,  0.1174, -0.0652],\n",
      "          [ 0.4349, -0.0672,  0.1449, -0.0489],\n",
      "          [ 0.2405,  0.1285, -0.0370,  0.1158]],\n",
      "\n",
      "         [[ 0.1249, -0.0035,  0.1753, -0.9563],\n",
      "          [-0.3803, -0.0088, -0.1132,  0.0212],\n",
      "          [ 2.0497, -0.1870,  0.9492,  0.2277],\n",
      "          [ 0.2188,  0.1909, -0.2606,  0.1416]],\n",
      "\n",
      "         [[-0.0643, -0.2665,  1.0756, -0.2845],\n",
      "          [-0.0191,  0.8494,  0.2290, -0.2609],\n",
      "          [ 0.5532, -0.2796, -0.4791,  0.2532],\n",
      "          [ 0.0399, -0.4498, -0.7968,  0.3531]]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "Attention Score shape: torch.Size([2, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = queries @ keys.transpose(2,3)\n",
    "print(\"Attention Scores:\", attention_scores)\n",
    "print(\"Attention Score shape:\", attention_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb6b74d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1842,    -inf,    -inf,    -inf],\n",
       "          [ 0.0461, -0.0402,    -inf,    -inf],\n",
       "          [ 0.2044,  0.4954,  0.3333,    -inf],\n",
       "          [-0.5024, -0.0750,  0.2026, -0.0922]],\n",
       "\n",
       "         [[-0.1101,    -inf,    -inf,    -inf],\n",
       "          [-0.0037,  0.0497,    -inf,    -inf],\n",
       "          [ 0.4349, -0.0672,  0.1449,    -inf],\n",
       "          [ 0.2405,  0.1285, -0.0370,  0.1158]],\n",
       "\n",
       "         [[ 0.1249,    -inf,    -inf,    -inf],\n",
       "          [-0.3803, -0.0088,    -inf,    -inf],\n",
       "          [ 2.0497, -0.1870,  0.9492,    -inf],\n",
       "          [ 0.2188,  0.1909, -0.2606,  0.1416]],\n",
       "\n",
       "         [[-0.0643,    -inf,    -inf,    -inf],\n",
       "          [-0.0191,  0.8494,    -inf,    -inf],\n",
       "          [ 0.5532, -0.2796, -0.4791,    -inf],\n",
       "          [ 0.0399, -0.4498, -0.7968,  0.3531]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1842,    -inf,    -inf,    -inf],\n",
       "          [ 0.0461, -0.0402,    -inf,    -inf],\n",
       "          [ 0.2044,  0.4954,  0.3333,    -inf],\n",
       "          [-0.5024, -0.0750,  0.2026, -0.0922]],\n",
       "\n",
       "         [[-0.1101,    -inf,    -inf,    -inf],\n",
       "          [-0.0037,  0.0497,    -inf,    -inf],\n",
       "          [ 0.4349, -0.0672,  0.1449,    -inf],\n",
       "          [ 0.2405,  0.1285, -0.0370,  0.1158]],\n",
       "\n",
       "         [[ 0.1249,    -inf,    -inf,    -inf],\n",
       "          [-0.3803, -0.0088,    -inf,    -inf],\n",
       "          [ 2.0497, -0.1870,  0.9492,    -inf],\n",
       "          [ 0.2188,  0.1909, -0.2606,  0.1416]],\n",
       "\n",
       "         [[-0.0643,    -inf,    -inf,    -inf],\n",
       "          [-0.0191,  0.8494,    -inf,    -inf],\n",
       "          [ 0.5532, -0.2796, -0.4791,    -inf],\n",
       "          [ 0.0399, -0.4498, -0.7968,  0.3531]]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask_bool = (torch.tril(torch.ones(num_tokens,num_tokens))==0)\n",
    "attention_scores.masked_fill_(mask_bool,-torch.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "06545853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.5125, 0.4875, 0.0000, 0.0000],\n",
       "           [0.3067, 0.3628, 0.3304, 0.0000],\n",
       "           [0.1980, 0.2535, 0.2975, 0.2510]],\n",
       " \n",
       "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.4923, 0.5077, 0.0000, 0.0000],\n",
       "           [0.3855, 0.2885, 0.3260, 0.0000],\n",
       "           [0.2688, 0.2520, 0.2290, 0.2501]],\n",
       " \n",
       "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.4466, 0.5534, 0.0000, 0.0000],\n",
       "           [0.5541, 0.1523, 0.2935, 0.0000],\n",
       "           [0.2704, 0.2660, 0.2050, 0.2586]],\n",
       " \n",
       "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.3772, 0.6228, 0.0000, 0.0000],\n",
       "           [0.4610, 0.2850, 0.2540, 0.0000],\n",
       "           [0.2802, 0.2112, 0.1729, 0.3357]]],\n",
       " \n",
       " \n",
       "         [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.5125, 0.4875, 0.0000, 0.0000],\n",
       "           [0.3067, 0.3628, 0.3304, 0.0000],\n",
       "           [0.1980, 0.2535, 0.2975, 0.2510]],\n",
       " \n",
       "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.4923, 0.5077, 0.0000, 0.0000],\n",
       "           [0.3855, 0.2885, 0.3260, 0.0000],\n",
       "           [0.2688, 0.2520, 0.2290, 0.2501]],\n",
       " \n",
       "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.4466, 0.5534, 0.0000, 0.0000],\n",
       "           [0.5541, 0.1523, 0.2935, 0.0000],\n",
       "           [0.2704, 0.2660, 0.2050, 0.2586]],\n",
       " \n",
       "          [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "           [0.3772, 0.6228, 0.0000, 0.0000],\n",
       "           [0.4610, 0.2850, 0.2540, 0.0000],\n",
       "           [0.2802, 0.2112, 0.1729, 0.3357]]]], grad_fn=<SoftmaxBackward0>),\n",
       " torch.Size([2, 4, 4, 4]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "attention_weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "attention_weights = torch.dropout(attention_weights, p=0, train=True)\n",
    "\n",
    "attention_weights,attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d84f0502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0490, -0.9331,  0.7512],\n",
       "          [ 0.1413, -0.4448,  0.2627],\n",
       "          [-0.2899, -0.5274, -0.0349],\n",
       "          [-0.3392, -0.5007, -0.1556]],\n",
       "\n",
       "         [[ 0.3188, -0.6036,  0.4032],\n",
       "          [-0.0381, -0.2422,  0.1890],\n",
       "          [-0.0294, -0.6630,  0.1342],\n",
       "          [-0.2495, -0.4849, -0.0359]],\n",
       "\n",
       "         [[ 0.1633, -0.2368, -0.4353],\n",
       "          [-0.2652, -0.5139,  0.1809],\n",
       "          [ 0.2068,  0.0395, -0.2457],\n",
       "          [-0.1112, -0.2590,  0.2009]],\n",
       "\n",
       "         [[ 0.1264, -0.3258,  0.4194],\n",
       "          [ 0.1818,  0.0610, -0.2628],\n",
       "          [-0.0775, -0.3540,  0.0866],\n",
       "          [-0.3472, -0.1039, -0.2532]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0490, -0.9331,  0.7512],\n",
       "          [ 0.1413, -0.4448,  0.2627],\n",
       "          [-0.2899, -0.5274, -0.0349],\n",
       "          [-0.3392, -0.5007, -0.1556]],\n",
       "\n",
       "         [[ 0.3188, -0.6036,  0.4032],\n",
       "          [-0.0381, -0.2422,  0.1890],\n",
       "          [-0.0294, -0.6630,  0.1342],\n",
       "          [-0.2495, -0.4849, -0.0359]],\n",
       "\n",
       "         [[ 0.1633, -0.2368, -0.4353],\n",
       "          [-0.2652, -0.5139,  0.1809],\n",
       "          [ 0.2068,  0.0395, -0.2457],\n",
       "          [-0.1112, -0.2590,  0.2009]],\n",
       "\n",
       "         [[ 0.1264, -0.3258,  0.4194],\n",
       "          [ 0.1818,  0.0610, -0.2628],\n",
       "          [-0.0775, -0.3540,  0.0866],\n",
       "          [-0.3472, -0.1039, -0.2532]]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "context_vec = (attention_weights @ values.transpose(1,2)) \n",
    "context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36b88088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0490, -0.9331,  0.7512,  0.1413, -0.4448,  0.2627, -0.2899,\n",
       "           -0.5274, -0.0349, -0.3392, -0.5007, -0.1556],\n",
       "          [ 0.3188, -0.6036,  0.4032, -0.0381, -0.2422,  0.1890, -0.0294,\n",
       "           -0.6630,  0.1342, -0.2495, -0.4849, -0.0359],\n",
       "          [ 0.1633, -0.2368, -0.4353, -0.2652, -0.5139,  0.1809,  0.2068,\n",
       "            0.0395, -0.2457, -0.1112, -0.2590,  0.2009],\n",
       "          [ 0.1264, -0.3258,  0.4194,  0.1818,  0.0610, -0.2628, -0.0775,\n",
       "           -0.3540,  0.0866, -0.3472, -0.1039, -0.2532]],\n",
       " \n",
       "         [[ 0.0490, -0.9331,  0.7512,  0.1413, -0.4448,  0.2627, -0.2899,\n",
       "           -0.5274, -0.0349, -0.3392, -0.5007, -0.1556],\n",
       "          [ 0.3188, -0.6036,  0.4032, -0.0381, -0.2422,  0.1890, -0.0294,\n",
       "           -0.6630,  0.1342, -0.2495, -0.4849, -0.0359],\n",
       "          [ 0.1633, -0.2368, -0.4353, -0.2652, -0.5139,  0.1809,  0.2068,\n",
       "            0.0395, -0.2457, -0.1112, -0.2590,  0.2009],\n",
       "          [ 0.1264, -0.3258,  0.4194,  0.1818,  0.0610, -0.2628, -0.0775,\n",
       "           -0.3540,  0.0866, -0.3472, -0.1039, -0.2532]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " torch.Size([2, 4, 12]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "context_vec = context_vec.contiguous().view(b,num_tokens,d_out)\n",
    "context_vec, context_vec.shape\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
