{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe926d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea1e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = [{\"cat\":0, \"dog\": 1, \"chases\":2, \"mouse\": 3, \"the\":4}]\n",
    "logits = [[1.9,-2.1,-.3, .4, -.8],\n",
    "          [.3,2.5,-.5,0,-1.1],\n",
    "          [-.6,.2,1.4,-.9,-.2] ]\n",
    "targets = [1,0,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782715b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(v):\n",
    "    e_raised_vals = []\n",
    "    for i in range(len(v)):\n",
    "        e_raised_vals.append(math.exp(v[i]))\n",
    "    total = sum(e_raised_vals)\n",
    "    \n",
    "    probs = []\n",
    "    for value in e_raised_vals:\n",
    "        probs.append(value/total)\n",
    "    return probs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c044ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7044960025395535, 0.01290329438107122, 0.07806038213502133, 0.15719430587057923, 0.04734601507377475] 1.0\n",
      "[0.08724665367176511, 0.7874022271681335, 0.0392024485170282, 0.06463391073355108, 0.021514759909522087] 0.9999999999999999\n",
      "[0.07783773045595786, 0.17323105491069887, 0.5751473569525154, 0.05766360897828585, 0.11612024870254202] 1.0\n"
     ]
    }
   ],
   "source": [
    "#softmax each token\n",
    "\n",
    "probs = []\n",
    "for token_logits in logits:\n",
    "    p = softmax(token_logits)\n",
    "    probs.append(p)\n",
    "    print(p, sum(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7d6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate loss\n",
    "\n",
    "def cross_entropy_loss(pred_val, target):\n",
    "    return -math.log(pred_val[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c169551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.342417691863913, 2.4474725639546375)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total loss\n",
    "\n",
    "losses = []\n",
    "for i in range(len(targets)):\n",
    "    loss = cross_entropy_loss(probs[i], targets[i])\n",
    "    losses.append(loss)\n",
    "\n",
    "total_loss = sum(losses)\n",
    "avg_loss = total_loss/len(losses)\n",
    "\n",
    "total_loss, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf999ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
