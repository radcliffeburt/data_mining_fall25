{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a577d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57edbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4320c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make training faster on a laptop, change context_length as shown:\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b5282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744511e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26be878",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eceda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Magical physicist AttributionÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ sketchesbeenroughunctureKEYaned\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d589e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you forward\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3366315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probs = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probs.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016d2404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4987e-05, 2.5454e-05, 1.8972e-05,  ..., 6.6857e-06,\n",
       "          1.1202e-05, 1.2687e-05],\n",
       "         [2.3594e-05, 1.5475e-05, 3.8714e-05,  ..., 7.8224e-06,\n",
       "          1.5605e-05, 9.0045e-06],\n",
       "         [2.4167e-05, 1.7438e-05, 4.9356e-05,  ..., 3.4949e-05,\n",
       "          1.4113e-05, 1.4872e-05]],\n",
       "\n",
       "        [[1.1661e-05, 4.5103e-05, 4.5678e-05,  ..., 7.7209e-06,\n",
       "          6.4411e-06, 1.0182e-05],\n",
       "         [2.5758e-05, 3.1875e-05, 2.2354e-05,  ..., 1.2024e-05,\n",
       "          1.4817e-05, 1.5663e-05],\n",
       "         [1.5000e-05, 2.6626e-05, 6.5054e-05,  ..., 1.8256e-05,\n",
       "          1.1593e-05, 2.7085e-05]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02286211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[26711],\n",
      "         [ 6557],\n",
      "         [46612]],\n",
      "\n",
      "        [[34487],\n",
      "         [13791],\n",
      "         [33070]]])\n"
     ]
    }
   ],
   "source": [
    "# predicted tokens:\n",
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c5fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  prostateá waiter\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e208aa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 2:  really like chocolate\n",
      "Outputs batch 2: Pri grey cram\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39e34eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3626,  6100,   345],\n",
       "        [ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa9e1274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([2.1299e-05, 1.7519e-05, 1.5568e-05])\n",
      "Text 2: tensor([2.0574e-05, 1.8915e-05, 1.0504e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probs_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6b54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions( sci_mode=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18344499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.7568, -10.9522, -11.0703, -10.7915, -10.8755, -11.4638])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b08df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.9850)\n",
      "tensor(10.9850)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probs = torch.mean(log_probs)\n",
    "print(avg_log_probs)\n",
    "neg_avg_log_probs = avg_log_probs * -1\n",
    "print(neg_avg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cecc539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d014ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1166,  0.4131,  0.1192,  ..., -0.9238, -0.4077, -0.2832],\n",
      "        [ 0.3386, -0.0832,  0.8338,  ..., -0.7654, -0.0748, -0.6247],\n",
      "        [ 0.3640,  0.0377,  1.0781,  ...,  0.7329, -0.1739, -0.1215],\n",
      "        [-0.3704,  0.9823,  0.9950,  ..., -0.7827, -0.9639, -0.5060],\n",
      "        [ 0.4205,  0.6336,  0.2788,  ..., -0.3413, -0.1324, -0.0769],\n",
      "        [-0.1156,  0.4582,  1.3515,  ...,  0.0808, -0.3733,  0.4753]])\n",
      "tensor([ 3626,  6100,   345,  1107,   588, 11311])\n"
     ]
    }
   ],
   "source": [
    "print(logits_flat)\n",
    "print(targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4496e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9850)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da356f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58984.5117)\n"
     ]
    }
   ],
   "source": [
    "# a more interpretable version of cross entropy --\n",
    "# this is basically the number of tokens the model considers for predicted output\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8be5a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABOUT fifteen years ago, on a date late in August or early in September, a train drew up at Wilsthor\n"
     ]
    }
   ],
   "source": [
    "# use the short story from before for training:\n",
    "with open( \"humphreys.txt\", \"r\" ) as f:\n",
    "    text_data = f.read()\n",
    "print(text_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51a99344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate text into training and validation sets:\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "170dd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 12800\n",
      "Validation tokens: 1280\n",
      "All tokens: 14080\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eb08b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf190bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n",
      "Training loss: 10.98396583557129\n",
      "Validation loss: 10.992756207784018\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53faf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4661c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.712, Val loss 9.801\n",
      "Ep 1 (Step 000005): Train loss 8.146, Val loss 8.248\n",
      "Ep 1 (Step 000010): Train loss 6.962, Val loss 7.228\n",
      "Ep 1 (Step 000015): Train loss 6.521, Val loss 6.878\n",
      "Ep 1 (Step 000020): Train loss 6.037, Val loss 6.749\n",
      "Every effort moves you of the’, and the’, and the’, and the’, and thereys, and the of the of the of the of the’, and the of the of the of the of the of the of\n",
      "Ep 2 (Step 000025): Train loss 6.083, Val loss 6.643\n",
      "Ep 2 (Step 000030): Train loss 5.643, Val loss 6.565\n",
      "Ep 2 (Step 000035): Train loss 5.551, Val loss 6.543\n",
      "Ep 2 (Step 000040): Train loss 5.551, Val loss 6.542\n",
      "Ep 2 (Step 000045): Train loss 5.021, Val loss 6.468\n",
      "Every effort moves you’s the.’s the house, and I'm.’s the house, and the house, and that, and a maze.’s the house, and the house, and I'm of that, and that\n",
      "Ep 3 (Step 000050): Train loss 5.004, Val loss 6.350\n",
      "Ep 3 (Step 000055): Train loss 4.592, Val loss 6.401\n",
      "Ep 3 (Step 000060): Train loss 4.604, Val loss 6.409\n",
      "Ep 3 (Step 000065): Train loss 4.444, Val loss 6.354\n",
      "Ep 3 (Step 000070): Train loss 4.321, Val loss 6.349\n",
      "Every effort moves you know, and that it was a great.’s a maze.’s the temple, I'm, I'm not, I'm, I'm, I'm, I'm, I'm, I'm, I'm, I\n",
      "Ep 4 (Step 000075): Train loss 3.980, Val loss 6.312\n",
      "Ep 4 (Step 000080): Train loss 4.194, Val loss 6.363\n",
      "Ep 4 (Step 000085): Train loss 3.320, Val loss 6.347\n",
      "Ep 4 (Step 000090): Train loss 3.562, Val loss 6.412\n",
      "Ep 4 (Step 000095): Train loss 3.299, Val loss 6.369\n",
      "Every effort moves you see it was a good, and in a good, and it, and it was a good, and Mr. “Now, and it was a few, and here. “It. “Now,’t you’\n",
      "Ep 5 (Step 000100): Train loss 3.099, Val loss 6.402\n",
      "Ep 5 (Step 000105): Train loss 2.829, Val loss 6.377\n",
      "Ep 5 (Step 000110): Train loss 2.671, Val loss 6.471\n",
      "Ep 5 (Step 000115): Train loss 2.145, Val loss 6.457\n",
      "Ep 5 (Step 000120): Train loss 2.477, Val loss 6.489\n",
      "Every effort moves you on the house. “I should be I shall be, Mr. I've not the house.’s’s house, “I should have been the house.’s a good, if you’s house\n",
      "Ep 6 (Step 000125): Train loss 2.045, Val loss 6.538\n",
      "Ep 6 (Step 000130): Train loss 1.921, Val loss 6.535\n",
      "Ep 6 (Step 000135): Train loss 1.663, Val loss 6.623\n",
      "Ep 6 (Step 000140): Train loss 1.834, Val loss 6.626\n",
      "Ep 6 (Step 000145): Train loss 1.660, Val loss 6.643\n",
      "Every effort moves you see,’ “I think you have thought? I think I think of you must really forgive me.’s Religious Ceremon in my way, Mr.’ ‘that I can’t you’ll foll\n",
      "Ep 7 (Step 000150): Train loss 1.324, Val loss 6.719\n",
      "Ep 7 (Step 000155): Train loss 1.334, Val loss 6.786\n",
      "Ep 7 (Step 000160): Train loss 1.073, Val loss 6.867\n",
      "Ep 7 (Step 000165): Train loss 1.005, Val loss 6.846\n",
      "Ep 7 (Step 000170): Train loss 0.814, Val loss 6.887\n",
      "Every effort moves you’t you’t it is, Mr. Humphreys, I think your bailiff must be right about half-past ten in the morning. “It seems it. Humphreys,’s very well, I suppose.\n",
      "Ep 8 (Step 000175): Train loss 0.854, Val loss 6.970\n",
      "Ep 8 (Step 000180): Train loss 0.611, Val loss 6.908\n",
      "Ep 8 (Step 000185): Train loss 0.724, Val loss 7.045\n",
      "Ep 8 (Step 000190): Train loss 0.577, Val loss 7.064\n",
      "Ep 8 (Step 000195): Train loss 0.474, Val loss 7.154\n",
      "Every effort moves you've never seen that place so carefully locked?”  After this confident prelude justice would seem to require that Lady Wardrop should have been hopelessly muddled by the Wilsthorpe maze. Nothing of that kind happened: yet it\n",
      "Ep 9 (Step 000200): Train loss 0.403, Val loss 7.258\n",
      "Ep 9 (Step 000205): Train loss 0.360, Val loss 7.280\n",
      "Ep 9 (Step 000210): Train loss 0.320, Val loss 7.296\n",
      "Ep 9 (Step 000215): Train loss 0.457, Val loss 7.376\n",
      "Ep 9 (Step 000220): Train loss 0.390, Val loss 7.391\n",
      "Every effort moves you” so ran the passage, “whether in the way of Parable or true Relation I leave my Reader to judge, of a Man who, like Theseus, in the Attick Tale, should adventure himself, into a Labyrinth or\n",
      "Ep 10 (Step 000225): Train loss 0.284, Val loss 7.346\n",
      "Ep 10 (Step 000230): Train loss 0.276, Val loss 7.413\n",
      "Ep 10 (Step 000235): Train loss 0.265, Val loss 7.408\n",
      "Ep 10 (Step 000240): Train loss 0.184, Val loss 7.467\n",
      "Ep 10 (Step 000245): Train loss 0.206, Val loss 7.555\n",
      "Every effort moves you know———and, turning from it, addressed himself to his plan. After half an hour's work he found it was impossible to get on without using a clue: so he procured a roll of twine from Clutterham, and laid\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c992ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02a677d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know———and, turning from it, addressed himself to his plan. After half an hour's work he found it was\n"
     ]
    }
   ],
   "source": [
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a2fd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the book for more details and examples!\n",
    "# temperature scaling and top-k sampling together increase \n",
    "# the diversity of predictions\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5aad5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you see it just at a great portion of Cooper arrived at last? Oh:\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c25944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
