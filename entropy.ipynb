{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a577d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57edbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4320c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make training faster on a laptop, change context_length as shown:\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16b5282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "744511e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f26be878",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1eceda77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you digestion tenure Gibbs nurturing\":\"\",\" Earthchell fielded Slam weave\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d589e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you forward\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3366315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probs = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probs.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "016d2404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "              0.0000,     0.0000],\n",
       "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
       "              0.0000,     0.0000],\n",
       "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "              0.0000,     0.0000]],\n",
       "\n",
       "        [[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "              0.0000,     0.0000],\n",
       "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "              0.0000,     0.0000],\n",
       "         [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "              0.0000,     0.0000]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02286211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[45219],\n",
      "         [31750],\n",
      "         [21549]],\n",
      "\n",
      "        [[30149],\n",
      "         [48977],\n",
      "         [29186]]])\n"
     ]
    }
   ],
   "source": [
    "# predicted tokens:\n",
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1c5fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  sten Hicks Clint\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e208aa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 2:  really like chocolate\n",
      "Outputs batch 2:  Bound joyful Strat\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d39e34eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3626,  6100,   345],\n",
       "        [ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa9e1274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0000,     0.0000,     0.0001])\n",
      "Text 2: tensor([    0.0000,     0.0000,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probs_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad6b54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions( sci_mode=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18344499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.6540, -10.4914,  -9.4586, -11.2973, -11.7150, -11.3721])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b08df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8314)\n",
      "tensor(10.8314)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probs = torch.mean(log_probs)\n",
    "print(avg_log_probs)\n",
    "neg_avg_log_probs = avg_log_probs * -1\n",
    "print(neg_avg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cecc539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d014ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1739, -0.3948, -0.4464,  ...,  0.1809,  0.2167, -0.1635],\n",
      "        [ 0.4661, -0.2151,  0.8659,  ...,  1.3645,  0.7442, -0.4392],\n",
      "        [ 0.4442, -0.4762,  0.4601,  ..., -0.0663, -0.2932, -0.8321],\n",
      "        [ 0.9304, -0.0179, -0.2177,  ..., -0.0909, -0.6040, -0.6172],\n",
      "        [ 0.6668, -0.6059,  0.0620,  ...,  0.2051,  0.0606, -0.5502],\n",
      "        [ 0.8367,  0.1875, -1.1209,  ...,  0.0495, -0.4566, -0.6217]])\n",
      "tensor([ 3626,  6100,   345,  1107,   588, 11311])\n"
     ]
    }
   ],
   "source": [
    "print(logits_flat)\n",
    "print(targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd4496e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8314)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da356f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50585.8711)\n"
     ]
    }
   ],
   "source": [
    "# a more interpretable version of cross entropy --\n",
    "# this is basically the number of tokens the model considers for predicted output\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8be5a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cororuc glanced about him and hastened his pace. He was no coward, but he did not like the place. Ta\n"
     ]
    }
   ],
   "source": [
    "# use the short story from before for training:\n",
    "with open( \"thelostrace.txt\", \"r\" ) as f:\n",
    "    text_data = f.read()\n",
    "print(text_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ec615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51a99344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate text into training and validation sets:\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "170dd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 6144\n",
      "Validation tokens: 512\n",
      "All tokens: 6656\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eb08b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddf190bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.983151276906332\n",
      "Validation loss: 10.959850311279297\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53faf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4661c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.685, Val loss 9.879\n",
      "Ep 1 (Step 000005): Train loss 8.063, Val loss 8.323\n",
      "Ep 1 (Step 000010): Train loss 6.796, Val loss 7.355\n",
      "Every effort moves you.                                                 \n",
      "Ep 2 (Step 000015): Train loss 6.129, Val loss 6.998\n",
      "Ep 2 (Step 000020): Train loss 5.761, Val loss 6.973\n",
      "Every effort moves you, and a, and a, and, and, and, and, and, and a, and, and, and, and a, and, and, and of the of the of the of the of the forest, and, and,\n",
      "Ep 3 (Step 000025): Train loss 5.650, Val loss 6.913\n",
      "Ep 3 (Step 000030): Train loss 5.577, Val loss 6.934\n",
      "Ep 3 (Step 000035): Train loss 5.413, Val loss 6.868\n",
      "Every effort moves you, and                                                \n",
      "Ep 4 (Step 000040): Train loss 5.420, Val loss 6.839\n",
      "Ep 4 (Step 000045): Train loss 5.401, Val loss 7.011\n",
      "Every effort moves you, and a a                                              \n",
      "Ep 5 (Step 000050): Train loss 4.957, Val loss 6.810\n",
      "Ep 5 (Step 000055): Train loss 4.914, Val loss 6.841\n",
      "Every effort moves you, but the forest.                                             \n",
      "Ep 6 (Step 000060): Train loss 4.544, Val loss 6.705\n",
      "Ep 6 (Step 000065): Train loss 4.069, Val loss 6.651\n",
      "Ep 6 (Step 000070): Train loss 3.775, Val loss 6.731\n",
      "Every effort moves you, and a long.                                             \n",
      "Ep 7 (Step 000075): Train loss 3.415, Val loss 6.719\n",
      "Ep 7 (Step 000080): Train loss 3.289, Val loss 6.748\n",
      "Every effort moves you, but the forest.                       \"But, and the Briton,\" the Briton was of the Briton was, and then. \n",
      "Ep 8 (Step 000085): Train loss 2.925, Val loss 6.719\n",
      "Ep 8 (Step 000090): Train loss 2.682, Val loss 6.740\n",
      "Ep 8 (Step 000095): Train loss 2.282, Val loss 6.737\n",
      "Every effort moves you the west and the forest.                      \"But the Picts, the Briton,\" the Picts in the race of the Picts,\" the\n",
      "Ep 9 (Step 000100): Train loss 1.756, Val loss 6.782\n",
      "Ep 9 (Step 000105): Train loss 1.684, Val loss 6.805\n",
      "Every effort moves you and burn dwellings, and the forest.             \" the caves, and the Briton!\" Cororuc was in his feet in the Briton!\" Cororuc was on his feet.\n",
      "Ep 10 (Step 000110): Train loss 1.478, Val loss 6.881\n",
      "Ep 10 (Step 000115): Train loss 1.183, Val loss 6.918\n",
      "Every effort moves you greatly desiring to do so.               And, the Briton,\" said the Briton,\" was in the Briton,\" the Briton!\" The forest, his feet in the\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c992ca61",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     plt.show()\n\u001b[32m     25\u001b[39m epochs_tensor = torch.linspace(\u001b[32m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mplot_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens_seen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mplot_losses\u001b[39m\u001b[34m(epochs_seen, tokens_seen, train_losses, val_losses)\u001b[39m\n\u001b[32m      6\u001b[39m fig, ax1 = plt.subplots(figsize=(\u001b[32m5\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Plot training and validation loss against epochs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43max1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_seen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m ax1.plot(epochs_seen, val_losses, linestyle=\u001b[33m\"\u001b[39m\u001b[33m-.\u001b[39m\u001b[33m\"\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mValidation loss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m ax1.set_xlabel(\u001b[33m\"\u001b[39m\u001b[33mEpochs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\matplotlib\\axes\\_base.py:483\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    480\u001b[39m         kw[prop_name] = val\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) == \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     x = \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m     y = _check_1d(xy[\u001b[32m1\u001b[39m])\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\matplotlib\\cbook.py:1361\u001b[39m, in \u001b[36m_check_1d\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1359\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[32m   1360\u001b[39m \u001b[38;5;66;03m# Unpack in case of e.g. Pandas or xarray object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m x = \u001b[43m_unpack_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[32m   1363\u001b[39m \u001b[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[32m   1364\u001b[39m \u001b[38;5;66;03m# Note this will strip unit information.\u001b[39;00m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m'\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1366\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m'\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1367\u001b[39m         \u001b[38;5;28mlen\u001b[39m(x.shape) < \u001b[32m1\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\matplotlib\\cbook.py:2387\u001b[39m, in \u001b[36m_unpack_to_numpy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2381\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m xtmp\n\u001b[32m   2382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_jax_array(x) \u001b[38;5;129;01mor\u001b[39;00m _is_tensorflow_array(x):\n\u001b[32m   2383\u001b[39m     \u001b[38;5;66;03m# using np.asarray() instead of explicitly __array__(), as the latter is\u001b[39;00m\n\u001b[32m   2384\u001b[39m     \u001b[38;5;66;03m# only _one_ of many methods, and it's the last resort, see also\u001b[39;00m\n\u001b[32m   2385\u001b[39m     \u001b[38;5;66;03m# https://numpy.org/devdocs/user/basics.interoperability.html#using-arbitrary-objects-in-numpy\u001b[39;00m\n\u001b[32m   2386\u001b[39m     \u001b[38;5;66;03m# therefore, let arrays do better if they can\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2387\u001b[39m     xtmp = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2389\u001b[39m     \u001b[38;5;66;03m# In case np.asarray method does not return a numpy array in future\u001b[39;00m\n\u001b[32m   2390\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xtmp, np.ndarray):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\_tensor.py:1226\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02a677d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you greatly desiring to do so.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "And, the\n"
     ]
    }
   ],
   "source": [
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a2fd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the book for more details and examples!\n",
    "# temperature scaling and top-k sampling together increase \n",
    "# the diversity of predictions\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5aad5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you greatly desiring to do so.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=1,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c25944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
